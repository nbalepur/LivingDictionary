{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as urllib2\n",
    "import requests\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(topic, num_p):\n",
    "    \n",
    "    s = \"+\".join(topic.split(\" \"))\n",
    "    url = f\"https://google.com/search?q={s}\"\n",
    "    \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "    \n",
    "    for div in soup.find_all(\"div\", class_ = \"g\"):\n",
    "        print(div)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json \n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(topic, num_p):\n",
    "    cleaned_text = load_data()\n",
    "    \n",
    "    print(cleaned_text)\n",
    "    return\n",
    "    \n",
    "    tokenized_text = tokenizer.encode(cleaned_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    summary_ids = model.generate(tokenized_text,\n",
    "                                        num_beams=4,\n",
    "                                        no_repeat_ngram_size=2,\n",
    "                                        min_length=30,\n",
    "                                        max_length=100,\n",
    "                                        early_stopping=True)\n",
    "\n",
    "    output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "summarize(\"Machine Learning Examples\", 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Article\n",
      "------\n",
      "Image recognition is one of the most common applications of machine learning. It is used to identify objects, persons, places, digital images, etc. The popular use case of image recognition and face detection is, Automatic friend tagging suggestion:.Speech recognition is a process of converting voice instructions into text, and it is also known as \"Speech to text\", or \"Computer speech recognition.\" At present, machine learning algorithms are widely used by various applications of speech recognition. Google assistant, Siri, Cortana, and Alexa are using speech recognition technology to follow the voice instructions. Machine learning is widely used by various e-commerce and entertainment companies such as Amazon, Netflix, etc., for product recommendation to the user. Whenever we search for some product on Amazon, then we started getting an advertisement for the same product while internet surfing on the same browser and this is because of machine learning. One of the most exciting applications of machine learning is self-driving cars. Machine learning plays a significant role in self-driving cars. Tesla, the most popular car manufacturing company is working on self-driving car. It is using unsupervised learning method to train the car models to detect people and objects while driving. Machine learning is making our online transaction safe and secure by detecting fraud transaction. Whenever we perform some online transaction, there may be various ways that a fraudulent transaction can take place such as fake accounts, fake ids, and steal money in the middle of a transaction. So to detect this, Feed Forward Neural network helps us by checking whether it is a genuine transaction or a fraud transaction. One of the most common applications of Machine Learning is Automatic Friend Tagging Suggestions in Facebook or any other social media platform. Facebook uses face detection and Image recognition to automatically find the face of the person which matches itâ€™s Database and hence suggests us to tag that person based on DeepFace. Machine learning (ML) is the study of computer algorithms that can improve automatically through experience and by the use of data. It is seen as a part of artificial intelligence. Machine learning algorithms build a model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to do so. Machine learning algorithms are used in a wide variety of applications, such as in medicine, email filtering, speech recognition, and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.\n",
      "\n",
      "\n",
      "\n",
      "Summary\n",
      "------\n",
      ". Machine learning is the study of computer algorithms that can improve automatically through experience and by the use of data. Machine learning algorithms are used in a wide variety of applications, such as in medicine, email filtering, speech recognition, and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.\n"
     ]
    }
   ],
   "source": [
    "text = \". \".join(open(\"data.txt\", \"r\").read().split(\"\\n\"))\n",
    "cleaned_text = text.replace(\"..\", \". \").replace(\" . \", \"\")\n",
    "\n",
    "print(f\"Full Article\\n------\")\n",
    "print(cleaned_text)\n",
    "\n",
    "tokenized_text = tokenizer.encode(cleaned_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "summary_ids = model.generate(tokenized_text,\n",
    "                                    num_beams=6,\n",
    "                                    no_repeat_ngram_size=4,\n",
    "                                    min_length=50,\n",
    "                                    max_length=150,\n",
    "                                    early_stopping=True)\n",
    "\n",
    "output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "print(f\"\\n\\n\\nSummary\\n------\\n{output}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
