{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "755e837a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nishu\\Anaconda3\\envs\\haystack\\lib\\site-packages\\ray\\autoscaler\\_private\\cli_logger.py:57: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from haystack import *\n",
    "from haystack.document_stores import FAISSDocumentStore\n",
    "from haystack.schema import Document\n",
    "from haystack.nodes import DensePassageRetriever, FARMReader\n",
    "from haystack.pipelines import ExtractiveQAPipeline\n",
    "from haystack.utils import print_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c9b2947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85ec750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_docs(directory):\n",
    "    \n",
    "    import os\n",
    "    \n",
    "    docs = []\n",
    "\n",
    "    document_names = os.listdir(f\"./{directory}\")\n",
    "    texts = []\n",
    "    for doc in document_names:\n",
    "        texts.append(open(f\"{directory}/{doc}\",  encoding = 'utf8').read())\n",
    "    docs.append(Document(content = \"\\n\\n\".join(texts)))\n",
    "    \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed20d490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "document_store = FAISSDocumentStore(faiss_index_factory_str=\"Flat\")\n",
    "docs = create_docs(\"documents\")\n",
    "document_store.write_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86c1a5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = DensePassageRetriever(document_store=document_store,\n",
    "                                query_embedding_model=\"facebook/dpr-question_encoder-single-nq-base\",\n",
    "                                passage_embedding_model=\"facebook/dpr-ctx_encoder-single-nq-base\",\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2857458",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Updating Embedding:   0%|                                                                     | 0/7 [00:00<?, ? docs/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/16 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Documents Processed: 10000 docs [00:04, 2144.19 docs/s]                                                                \n"
     ]
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d1285a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/roberta-base-squad2 were not used when initializing RobertaModel: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at deepset/roberta-base-squad2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to log params: Changing param values is not allowed. Param with key='prediction_heads' was already logged with value='TextSimilarityHead' for run ID='5e4d07d5f83c4dc4be09ef515bc1edf6'. Attempted logging new value 'QuestionAnsweringHead'.\n",
      "Failed to log params: Changing param values is not allowed. Param with key='processor' was already logged with value='TextSimilarityProcessor' for run ID='5e4d07d5f83c4dc4be09ef515bc1edf6'. Attempted logging new value 'SquadProcessor'.\n",
      "ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n"
     ]
    }
   ],
   "source": [
    "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78d88455",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = ExtractiveQAPipeline(reader, retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6728de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question):\n",
    "    prediction = pipe.run(query = question, params={\"Retriever\": {\"top_k\": 10}, \"Reader\": {\"top_k\": 5}})\n",
    "    print_answers(prediction, details=\"minimal\")\n",
    "    \n",
    "# \"Machine Learning\"\n",
    "\"What are some applications of machine learning?\"\n",
    "\"Answer: Paragraph\"\n",
    "\n",
    "\"What is the history\"\n",
    "\"Answer: Paragraph\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62c25760",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 2/2 [00:43<00:00, 21.63s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.89s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.90s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.58s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:10<00:00, 10.37s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.63s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:12<00:00, 12.34s/ Batches]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   {   'answer': 'data mining, statistics, and modeling',\n",
      "        'context': 'to make predictions about the future. Techniques such as '\n",
      "                   'data mining, statistics, and modeling employ machine '\n",
      "                   'learning and artificial intelligence to '},\n",
      "    {   'answer': 'tracking monetary frauds online',\n",
      "        'context': 'proving its potential to make cyberspace a secure place '\n",
      "                   'and tracking monetary frauds online is one of its '\n",
      "                   'examples. For example: Paypal is using ML fo'},\n",
      "    {   'answer': 'tracking monetary frauds online',\n",
      "        'context': 'proving its potential to make cyberspace a secure place '\n",
      "                   'and tracking monetary frauds online is one of its '\n",
      "                   'examples. For example: Paypal is using ML fo'},\n",
      "    {   'answer': 'data mining, statistics, and modeling',\n",
      "        'context': 'to make predictions about the future. Techniques such as '\n",
      "                   'data mining, statistics, and modeling employ machine '\n",
      "                   'learning and artificial intelligence to '},\n",
      "    {   'answer': 'medical diagnosis, image processing, prediction, '\n",
      "                  'classification, learning association, regression',\n",
      "        'context': 'd industries. For example, medical diagnosis, image '\n",
      "                   'processing, prediction, classification, learning '\n",
      "                   'association, regression etc.\\n'\n",
      "                   '\\n'\n",
      "                   'The intelligent sys'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "answer_question(\"What are some applications of machine learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a0ac470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Execution took 118.66165709495544 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(f\"--- Execution took {(time.time() - start_time)} seconds ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
