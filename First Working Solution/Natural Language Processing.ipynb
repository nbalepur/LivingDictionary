{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af8c551c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as urllib2\n",
    "from googlesearch import search\n",
    "\n",
    "from haystack import *\n",
    "from haystack.document_stores import FAISSDocumentStore\n",
    "from haystack.schema import Document\n",
    "from haystack.nodes import DensePassageRetriever, FARMReader\n",
    "from haystack.pipelines import ExtractiveQAPipeline\n",
    "from haystack.utils import print_answers\n",
    "\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "030ff1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"Natural Language Processing\"\n",
    "headings = [\"Applications\", \"Types\", \"History\", \"Evaluation Metrics\"]\n",
    "questions = [f\"What are the {heading} of {topic}?\" for heading in headings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b6116d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_documents(urls):\n",
    "    \n",
    "    documents = []\n",
    "\n",
    "    for url in urls:\n",
    "\n",
    "        hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "        req = urllib2.Request(url, headers = hdr)\n",
    "        page = urllib2.urlopen(req)\n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        ps = []\n",
    "\n",
    "        for i, paragraph in enumerate(soup.findAll(\"p\")):\n",
    "            p = paragraph.text.split()\n",
    "            if len(p) == 0 or p[-1][-1] not in \".!,:;\":\n",
    "                continue\n",
    "            ps.append(\" \".join(p))\n",
    "            \n",
    "        text = \"\\n\".join(ps)\n",
    "        documents.append(Document(content = text))\n",
    "        \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82fc93a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_query(query, docs):\n",
    "    \n",
    "    document_store = FAISSDocumentStore(faiss_index_factory_str = \"Flat\")\n",
    "    document_store.write_documents(docs)\n",
    "    \n",
    "    retriever = DensePassageRetriever(document_store = document_store,\n",
    "                                query_embedding_model = \"facebook/dpr-question_encoder-single-nq-base\",\n",
    "                                passage_embedding_model = \"facebook/dpr-ctx_encoder-single-nq-base\",\n",
    "                                )\n",
    "    \n",
    "    document_store.update_embeddings(retriever)\n",
    "    \n",
    "    reader = FARMReader(model_name_or_path = \"deepset/roberta-base-squad2\")\n",
    "    \n",
    "    pipe = ExtractiveQAPipeline(reader, retriever)\n",
    "    \n",
    "    prediction = pipe.run(query = query, params = {\"Retriever\": {\"top_k\": 10}, \"Reader\": {\"top_k\": 5}})\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eb7653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_text(contexts, text):\n",
    "    \n",
    "    synth_text = \"\"\n",
    "\n",
    "    for context in contexts:\n",
    "        target = text.find(context)\n",
    "        start, end = target, target\n",
    "\n",
    "        while start >= 0:\n",
    "            if text[start] == \".\" or text[start] == \"\\n\":\n",
    "                start += 1\n",
    "                break\n",
    "            start -= 1\n",
    "\n",
    "        while end < len(text):\n",
    "            if (text[end] == \".\" or text[start] == \"\\n\") and (end - target) > len(context):\n",
    "                end += 1\n",
    "                break\n",
    "            end += 1\n",
    "\n",
    "        synth_text += text[start:end] + \" \"\n",
    "        \n",
    "    return synth_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "315331d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Updating Embedding:   0%|                                                                    | 0/67 [00:00<?, ? docs/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/80 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Documents Processed: 10000 docs [00:47, 211.43 docs/s]                                                                 \n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.72s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.84s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.73s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:08<00:00,  8.40s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.20s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.49s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:11<00:00, 11.14s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.32s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.37s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.23s/ Batches]\n",
      "Updating Embedding:   0%|                                                                    | 0/67 [00:00<?, ? docs/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/80 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Documents Processed: 10000 docs [00:47, 212.32 docs/s]                                                                 \n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.72s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.93s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.11s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.37s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:08<00:00,  8.53s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.49s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.34s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:10<00:00, 10.96s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.28s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.16s/ Batches]\n",
      "Updating Embedding:   0%|                                                                    | 0/71 [00:00<?, ? docs/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/80 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Documents Processed: 10000 docs [00:49, 202.51 docs/s]                                                                 \n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.64s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.76s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.62s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:09<00:00,  9.81s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.54s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.67s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.19s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.03s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.17s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:10<00:00, 10.98s/ Batches]\n",
      "Updating Embedding:   0%|                                                                    | 0/71 [00:00<?, ? docs/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/80 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Documents Processed: 10000 docs [00:49, 202.34 docs/s]                                                                 \n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.98s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.58s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.53s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.74s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.96s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.34s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.39s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:08<00:00,  8.29s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.17s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.39s/ Batches]\n"
     ]
    }
   ],
   "source": [
    "heading_texts = []\n",
    "heading_answers = []\n",
    "\n",
    "for heading in headings:\n",
    "\n",
    "    query = f\"What are {heading} of {topic}?\"\n",
    "    urls = [url for url in search(query, tld = \"co.in\", num = 5, stop = 5, pause = 2)]    \n",
    "    docs = create_documents(urls)\n",
    "    \n",
    "    prediction = answer_query(query, docs)\n",
    "    \n",
    "    contexts = [answer.context for answer in prediction[\"answers\"]]\n",
    "    answers = [answer.answer for answer in prediction[\"answers\"]]\n",
    "    text = \"\".join([pred.content for pred in prediction[\"documents\"]])\n",
    "    \n",
    "    synth_text = synthesize_text(contexts, text)\n",
    "    \n",
    "    heading_texts.append(synth_text)\n",
    "    heading_answers.append(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cfa9909",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<u><h1>Natural Language Processing</h1></u><br /><h3>What are the Applications of Natural Language Processing?</h3>\n",
       "<ul><li>grammar checking software and auto-correct functions</li><li>symbolic, statistical natural language and speech processing</li><li>machine translation, question answering, text summarization, image captioning, sentiment analysis</li><li>automated reasoning,[3] machine translation,[4] question answering,[5] news-gathering, text categorization, voice-activation, archiving, and large-scale content analysis</li><li>machine translation</li></ul>\n",
       "<p>Natural Language Processing plays a vital role in grammar checking software and auto-correct functions. Tools like Grammarly, for example, use NLP to help you improve your writing, by detecting grammar, spelling, or sentence structure errors.  They are suites of libraries, frameworks, and applications for symbolic, statistical natural language and speech processing.\n",
       "Chatterbot – a text-based conversation agent that can interact with human users through some medium, such as an instant message service.  It consists of many tasks like Machine translation, Question Answering, Text Summarization, Image captioning, Sentiment Analysis, etc. Researchers try to make different machine learning and deep learning models to solve these tasks. There is considerable commercial interest in the field because of its application to automated reasoning,[3] machine translation,[4] question answering,[5] news-gathering, text categorization, voice-activation, archiving, and large-scale content analysis.\n",
       "The program STUDENT, written in 1964 by Daniel Bobrow for his PhD dissertation at MIT, is one of the earliest known attempts at natural-language understanding by a computer.  Combined with sentiment analysis, keyword extraction can add an extra layer of insight, by telling you which words customers used most often to express negativity toward your product or service.\n",
       "Try out this online keyword extractor:\n",
       "Machine translation (MT) is one of the first applications of natural language processing. </p><br/><h3>What are the Types of Natural Language Processing?</h3>\n",
       "<ul><li>machine translation, question answering, text summarization, image captioning, sentiment analysis, etc</li><li>english-like sentences</li><li>speech, print, writing, and signing</li><li>linguistics, computer science, and artificial intelligence</li><li>artificial</li></ul>\n",
       "<p> It consists of many tasks like Machine translation, Question Answering, Text Summarization, Image captioning, Sentiment Analysis, etc. Researchers try to make different machine learning and deep learning models to solve these tasks. Throughout the years various attempts at processing natural language or English-like sentences presented to computers have taken place at varying degrees of complexity.  Natural language processing is also the name of the branch of computer science, artificial intelligence, and linguistics concerned with enabling computers to engage in communication using natural language(s) in all forms, including but not limited to speech, print, writing, and signing.\n",
       "Natural language processing can be described as all of the following:\n",
       "The following technologies make natural language processing possible:\n",
       "Natural language processing contributes to, and makes use of (the theories, tools, and methodologies from), the following fields:\n",
       "Natural language generation – task of converting information from computer databases into readable human language. Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data. In order to maintain successful operations, you need to be there for your customers when they...\n",
       "Natural language processing (NLP) is a type of artificial...\n",
       "Natural language processing (NLP) allows for the generation... </p><br/><h3>What are the History of Natural Language Processing?</h3>\n",
       "<ul><li>the advances of natural language processing</li><li>1950s</li><li>computer science, artificial intelligence, and linguistics</li><li>to analyze the surveys and generate insights from them</li><li>over the past two decades</li></ul>\n",
       "<p> Challenges in natural language processing frequently involve speech recognition, natural language understanding, and natural language generation.\n",
       "Natural language processing has its roots in the 1950s. Already in 1950, Alan Turing published an article titled \"Computing Machinery and Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence, a task that involves the automated interpretation and generation of natural language, but at the time not articulated as a problem separate from artificial intelligence.  Natural language processing is also the name of the branch of computer science, artificial intelligence, and linguistics concerned with enabling computers to engage in communication using natural language(s) in all forms, including but not limited to speech, print, writing, and signing.  That’s where companies use natural language processing to analyze the surveys and generate insights from them, like knowing the sentiments of users about an event from the feedbacks and analyzing product reviews to understand the pros and cons.  Hence, language is one of the most discussed concepts for AI professionals. Over the past two decades, rapid progress has been recorded in the field of Natural Language Processing (NLP). </p><br/><h3>What are the Evaluation Metrics of Natural Language Processing?</h3>\n",
       "<ul><li>bleu and rogue(recall-oriented understudy for gisting evaluation)</li><li>keyword extraction</li><li>accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves</li><li>insights</li><li>bleu and rogue(recall-oriented understudy for gisting evaluation) metrics</li></ul>\n",
       "<p>The evaluation of these tasks is done using BLEU and ROGUE(Recall-Oriented Understudy for Gisting Evaluation) metrics.\n",
       "It is a benchmark developed by Google for the evaluation of 40 languages on 9 different tasks.  You could pull out the information you need and set up a trigger to automatically enter this information in your database.\n",
       "Keyword extraction, on the other hand, gives you an overview of the content of a text, as this free natural language processing model shows.  The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.\n",
       "Challenges in natural language processing frequently involve speech recognition, natural language understanding, and natural language generation. Natural language processing tools can help businesses analyze data and discover insights, automate time-consuming processes, and help them gain a competitive advantage. The evaluation of these tasks is done using BLEU and ROGUE(Recall-Oriented Understudy for Gisting Evaluation) metrics.\n",
       "It is a benchmark developed by Google for the evaluation of 40 languages on 9 different tasks. </p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wiki_sections = [f\"<h3>{questions[i]}</h3>\\n<ul>{''.join([f'<li>{answer.lower()}</li>' for answer in heading_answers[i]])}</ul>\\n<p>{heading_texts[i]}</p>\" for i in range(len(headings))]\n",
    "body_text = \"<br/>\".join(wiki_sections)\n",
    "wiki_text = f\"<u><h1>{topic}</h1></u><br />{body_text}\"\n",
    "\n",
    "display(HTML(wiki_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
