{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as urllib2\n",
    "from googlesearch import search\n",
    "\n",
    "from haystack import *\n",
    "from haystack.document_stores import FAISSDocumentStore\n",
    "from haystack.schema import Document\n",
    "from haystack.nodes import DensePassageRetriever, FARMReader\n",
    "from haystack.pipelines import ExtractiveQAPipeline\n",
    "from haystack.utils import print_answers\n",
    "\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"Machine Learning\"\n",
    "headings = [\"Applications\", \"Types\", \"Current Research\", \"Evaluation Metrics\"]\n",
    "questions = [f\"What are {heading} of {topic}?\" for heading in headings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_documents(urls):\n",
    "    \n",
    "    documents = []\n",
    "\n",
    "    for url in urls:\n",
    "\n",
    "        hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "        req = urllib2.Request(url, headers = hdr)\n",
    "        page = urllib2.urlopen(req)\n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        ps = []\n",
    "\n",
    "        for i, paragraph in enumerate(soup.findAll(\"p\")):\n",
    "            p = paragraph.text.split()\n",
    "            if len(p) == 0 or p[-1][-1] not in \".!,:;\":\n",
    "                continue\n",
    "            ps.append(\" \".join(p))\n",
    "            \n",
    "        text = \"\\n\".join(ps)\n",
    "        documents.append(Document(content = text))\n",
    "        \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_query(query, docs):\n",
    "    \n",
    "    document_store = FAISSDocumentStore(faiss_index_factory_str = \"Flat\")\n",
    "    document_store.write_documents(docs)\n",
    "    \n",
    "    retriever = DensePassageRetriever(document_store = document_store,\n",
    "                                query_embedding_model = \"facebook/dpr-question_encoder-single-nq-base\",\n",
    "                                passage_embedding_model = \"facebook/dpr-ctx_encoder-single-nq-base\",\n",
    "                                )\n",
    "    \n",
    "    document_store.update_embeddings(retriever)\n",
    "    \n",
    "    reader = FARMReader(model_name_or_path = \"deepset/roberta-base-squad2\")\n",
    "    \n",
    "    pipe = ExtractiveQAPipeline(reader, retriever)\n",
    "    \n",
    "    prediction = pipe.run(query = query, params = {\"Retriever\": {\"top_k\": 10}, \"Reader\": {\"top_k\": 5}})\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_text(contexts, text):\n",
    "    \n",
    "    synth_text = \"\"\n",
    "\n",
    "    for context in contexts:\n",
    "        target = text.find(context)\n",
    "        start, end = target, target\n",
    "\n",
    "        while start >= 0:\n",
    "            if text[start] == \".\" or text[start] == \"\\n\":\n",
    "                start += 1\n",
    "                break\n",
    "            start -= 1\n",
    "\n",
    "        while end < len(text):\n",
    "            if (text[end] == \".\" or text[start] == \"\\n\") and (end - target) > len(context):\n",
    "                end += 1\n",
    "                break\n",
    "            end += 1\n",
    "\n",
    "        synth_text += text[start:end] + \" \"\n",
    "        \n",
    "    return synth_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Updating Embedding:   0%|                                                                    | 0/29 [00:00<?, ? docs/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd34c2c259a45d693d791ed632dcdda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/32 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Documents Processed: 10000 docs [00:18, 527.15 docs/s]                                                                 \n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.30s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.81s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:11<00:00, 11.22s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.01s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:20<00:00, 20.16s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.90s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.63s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:07<00:00,  7.90s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:07<00:00,  7.32s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.62s/ Batches]\n",
      "Updating Embedding:   0%|                                                                    | 0/30 [00:00<?, ? docs/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b0f1bfc40648dfb97f924e39ad1caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/32 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Documents Processed: 10000 docs [00:19, 508.92 docs/s]                                                                 \n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.34s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.89s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:11<00:00, 11.47s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.17s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:20<00:00, 20.73s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.62s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.95s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:07<00:00,  7.94s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:07<00:00,  7.29s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.87s/ Batches]\n",
      "Updating Embedding:   0%|                                                                    | 0/35 [00:00<?, ? docs/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "201427460a9e45cda7c6cd281deb5ca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/48 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Documents Processed: 10000 docs [00:23, 432.43 docs/s]                                                                 \n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.42s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.84s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.22s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.11s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:20<00:00, 20.79s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:11<00:00, 11.32s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:07<00:00,  7.40s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:08<00:00,  8.03s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.69s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.99s/ Batches]\n",
      "Updating Embedding:   0%|                                                                    | 0/35 [00:00<?, ? docs/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22d8e5ebb794bf4b1d4b2e91b80a37c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/48 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Documents Processed: 10000 docs [00:22, 435.11 docs/s]                                                                 \n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.40s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.79s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.30s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.79s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:11<00:00, 11.36s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:20<00:00, 20.53s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.14s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:08<00:00,  8.03s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.98s/ Batches]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:07<00:00,  7.35s/ Batches]\n"
     ]
    }
   ],
   "source": [
    "heading_texts = []\n",
    "heading_answers = []\n",
    "\n",
    "for heading in headings:\n",
    "\n",
    "    query = f\"What are {heading} of {topic}?\"\n",
    "    urls = [url for url in search(query, tld = \"co.in\", num = 5, stop = 5, pause = 2)]    \n",
    "    docs = create_documents(urls)\n",
    "    \n",
    "    prediction = answer_query(query, docs)\n",
    "    \n",
    "    contexts = [answer.context for answer in prediction[\"answers\"]]\n",
    "    answers = [answer.answer for answer in prediction[\"answers\"]]\n",
    "    text = \"\".join([pred.content for pred in prediction[\"documents\"]])\n",
    "    \n",
    "    synth_text = synthesize_text(contexts, text)\n",
    "    \n",
    "    heading_texts.append(synth_text)\n",
    "    heading_answers.append(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<u><h1>Machine Learning</h1></u><br /><h3>What are Applications of Machine Learning?</h3>\n",
       "<ul><li>classification</li><li>extraction of information</li><li>self-driving cars</li><li>web usage mining, intrusion detection, continuous production, and bioinformatics</li><li>automatic friend tagging suggestions</li></ul>\n",
       "<p>Feature learning is motivated by the fact that machine learning tasks such as classification often require input that is mathematically and computationally convenient to process.  Making predictions is one of the best machine learning applications.\n",
       "\n",
       "Extraction of information is one of the best applications of machine learning. It is the process of extracting structured information from the unstructured data. , and this is also done with the help of machine learning.\n",
       "One of the most exciting applications of machine learning is self-driving cars. Machine learning plays a significant role in self-driving cars. Tesla, the most popular car manufacturing company is working on self-driving car.  In addition to market basket analysis, association rules are employed today in application areas including Web usage mining, intrusion detection, continuous production, and bioinformatics. In contrast with sequence mining, association rule learning typically does not consider the order of items either within a transaction or across transactions. One of the most common applications of Machine Learning is Automatic Friend Tagging Suggestions in Facebook or any other social media platform. Facebook uses face detection and Image recognition to automatically find the face of the person which matches it’s Database and hence suggests us to tag that person based on DeepFace. </p><br/><h3>What are Types of Machine Learning?</h3>\n",
       "<ul><li>supervised learning, unsupervised learning, and reinforcement learning</li><li>supervised learning, unsupervised learning, and reinforcement learning</li><li>supervised, semi-supervised, unsupervised and reinforcement</li><li>regressions and classifications</li><li>three</li></ul>\n",
       "<p> Broadly speaking, Machine Learning algorithms are of three types- Supervised Learning, Unsupervised Learning, and Reinforcement Learning. A basic understanding of the different types of algorithms will help you choose an algorithm for your project or will simply help you appreciate the vast variety of problems AI can solve using Machine Learning.  There are many ways to frame this idea, but largely there are three major recognized categories: supervised learning, unsupervised learning, and reinforcement learning.\n",
       "In a world saturated by artificial intelligence, machine learning, and over-zealous talk about both, it is interesting to learn to understand and identify the types of machine learning we may encounter. There are four types of machine learning algorithms: supervised, semi-supervised, unsupervised and reinforcement.\n",
       "In supervised learning, the machine is taught by example. There are two further categories into which we can divide supervised learning: regressions and classifications, and each has its own set of use cases and merits. Common supervised learning algorithms include: Linear regression; Naïve Bayes, Nearest Neighbours, Decision Trees, Support Vector Machines and Neural Networks.  So long as we connect all these components together, we will have set up a reinforcement learning scenario to play the game Mario.\n",
       "Now that we’ve discussed the three different categories of machine learning, it’s important to note that a lot of times the lines between these types of learning blur. </p><br/><h3>What are Current Research of Machine Learning?</h3>\n",
       "<ul><li>classification</li><li>computational mathematics and statistics</li><li>theoretical and mathematical modeling</li><li>algorithms and neural network models</li><li>mathematical optimization</li></ul>\n",
       "<p>Feature learning is motivated by the fact that machine learning tasks such as classification often require input that is mathematically and computationally convenient to process. Machine Learning is a domain of computer science with its base in computational mathematics and statistics. The machine is shown a ton of data and it learns the pattern in the data to make future predictions, recognise new patterns or suggest different classes to the data.  On the research-side of things, machine learning can be viewed through the lens of theoretical and mathematical modeling of how this process works. However, more practically it is the study of how to build applications that exhibit this iterative improvement. Machine learning is a necessary aspect of modern business and research for many organizations today. It uses algorithms and neural network models to assist computer systems in progressively improving their performance. A subset of machine learning is closely related to computational statistics, which focuses on making predictions using computers; but not all machine learning is statistical learning. The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning. </p><br/><h3>What are Evaluation Metrics of Machine Learning?</h3>\n",
       "<ul><li>accuracy_score</li><li>hidden layers</li><li>ability to reproduce known knowledge</li><li>three</li><li>k-means and hierarchical clustering</li></ul>\n",
       "<p> Your model may give you satisfying results when evaluated using a metric say accuracy_score but may give poor results when evaluated against other metrics such as logarithmic_loss or any other such metric.  Neural networks use input and output layers and, normally, include a hidden layer (or layers) designed to transform input into data that can be used the by output layer. The hidden layers are excellent for finding patterns too complex for a human programmer to detect, meaning a human could not find the pattern and then teach the device to recognize it.  Much of the confusion between these two research communities (which do often have separate conferences and separate journals, ECML PKDD being a major exception) comes from the basic assumptions they work with: in machine learning, performance is usually evaluated with respect to the ability to reproduce known knowledge, while in knowledge discovery and data mining (KDD) the key task is the discovery of previously unknown knowledge.  So long as we connect all these components together, we will have set up a reinforcement learning scenario to play the game Mario.\n",
       "Now that we’ve discussed the three different categories of machine learning, it’s important to note that a lot of times the lines between these types of learning blur.  The most common use of unsupervised learning is in clustering problems, with the most talked about algorithms being k-means and hierarchical clustering, though other algorithms like Hidden Markov models, Self-Organizing Maps or Gaussian Mixture models are also often used. </p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wiki_sections = [f\"<h3>{questions[i]}</h3>\\n<ul>{''.join([f'<li>{answer.lower()}</li>' for answer in heading_answers[i]])}</ul>\\n<p>{heading_texts[i]}</p>\" for i in range(len(headings))]\n",
    "body_text = \"<br/>\".join(wiki_sections)\n",
    "wiki_text = f\"<u><h1>{topic}</h1></u><br />{body_text}\"\n",
    "\n",
    "display(HTML(wiki_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
